{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bird.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-_wlMzvXDzY"
      },
      "source": [
        "#import libraries\n",
        "import keras\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import tensorflow as tf\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUBp0XGyxfC3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6NRaSnpXFTi"
      },
      "source": [
        "from google.colab import drive # to mount google drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWsG5FyILKwx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdUX6EHKXMW6"
      },
      "source": [
        "ls /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPltpXF5Xa75"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Bird_detection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEZqoS-Agklp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFgKP78ugR_I"
      },
      "source": [
        "DIR_TRAIN = \"train\"\n",
        "DIR_VALID = \"valid\"\n",
        "DIR_TEST = \"test\"\n",
        "\n",
        "#print('number of male training images - ',len(os.listdir(DIR_TRAIN)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLsaFUvfgnj1"
      },
      "source": [
        "#classes =  len(os.listdir(DIR_TRAIN))\n",
        "#print('number of male training images - ',classes)\n",
        "### Exploring Dataset\n",
        "train_imgs = []\n",
        "valid_imgs = []\n",
        "test_imgs = []\n",
        "classes = os.listdir(DIR_TRAIN)\n",
        "print(\"Total Classes: \",len(classes))\n",
        "\n",
        "#Counting total train, valid & test images\n",
        "\n",
        "train_count = 0\n",
        "valid_count = 0\n",
        "test_count = 0\n",
        "for _class in classes:\n",
        "  \n",
        "    train_count += len(os.listdir(DIR_TRAIN +\"/\"+ _class))\n",
        "    valid_count += len(os.listdir(DIR_VALID +\"/\"+ _class))\n",
        "    test_count += len(os.listdir(DIR_TEST +\"/\"+ _class))\n",
        "\n",
        "print(\"Total train images: \",train_count)\n",
        "print(\"Total valid images: \",valid_count)\n",
        "print(\"Total test images: \",test_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88wwVssNc6cm"
      },
      "source": [
        "train = os.listdir('train')\n",
        "for _class in train:\n",
        "    \n",
        "    for img in os.listdir(DIR_TRAIN + \"/\" + _class):\n",
        "        train_imgs.append(DIR_TRAIN + \"/\" + _class + \"/\" + img)\n",
        "    \n",
        "    for img in os.listdir(DIR_VALID + \"/\" + _class):\n",
        "        valid_imgs.append(DIR_VALID  + \"/\" + _class + \"/\" + img)\n",
        "        \n",
        "    for img in os.listdir(DIR_TEST + \"/\" + _class):\n",
        "        test_imgs.append(DIR_TEST  + \"/\" + _class + \"/\" + img)\n",
        "class_to_int = {classes[i] : i for i in range(len(classes))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLYpkHMjgeyN"
      },
      "source": [
        "### Loading Classification Dataset - FOR METHOD 2: For multi-class data, by inheriting Dataset class\n",
        "\n",
        "\n",
        "def get_transform():\n",
        "    return T.Compose([T.ToTensor()])\n",
        "\n",
        "class BirdDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, imgs_list, class_to_int, transforms = None):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.imgs_list = imgs_list\n",
        "        self.class_to_int = class_to_int\n",
        "        self.transforms = transforms\n",
        "        \n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "    \n",
        "        image_path = self.imgs_list[index]\n",
        "        \n",
        "        #Reading image\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        image /= 255.0\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        height, width, channels = image.shape\n",
        "\n",
        "        \n",
        "        \n",
        "        #Retriving class label\n",
        "        label = image_path.split(\"/\")[-2]\n",
        "        label = self.class_to_int[label]\n",
        "        \n",
        "        #Applying transforms on image\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        \n",
        "        return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQMXG8qDltDT"
      },
      "source": [
        "train_dataset = BirdDataset(train_imgs, class_to_int, get_transform())\n",
        "valid_dataset = BirdDataset(valid_imgs, class_to_int, get_transform())\n",
        "test_dataset = BirdDataset(test_imgs, class_to_int, get_transform())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMyNRdZVXfAY"
      },
      "source": [
        "#Creating generator for Training DataSet\n",
        "#Reading image\n",
        "        #image_path='train/'\n",
        "        #image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        #image /= 255.0\n",
        "         #image = cv2.resize(image, (224, 224))\n",
        "train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        './train/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')\n",
        "\n",
        "#Creating generator for Validation DataSet\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "        './valid/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "#Creating generator for Test DataSet\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        './test/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNwKg8tca7h0"
      },
      "source": [
        "#instantiate a base model with pre-trained weigts.\n",
        "base_model=keras.applications.VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMpuxaerkkha"
      },
      "source": [
        "#freeze the base model\n",
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yatJW-gkniS"
      },
      "source": [
        "#Create new model on top\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,Dropout\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2048,activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(2048,activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(225,activation='softmax',kernel_initializer='glorot_normal'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtIvWsRQkr2m"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH5ttghyLNVH"
      },
      "source": [
        "#Train the model on new data.\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history=model.fit(train_generator,epochs=30,validation_data=val_generator,workers=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFLhukM0LQ30"
      },
      "source": [
        "model.predict(\"gbjh.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}